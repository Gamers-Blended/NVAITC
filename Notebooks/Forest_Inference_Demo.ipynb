{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPjNdKSVv9I0"
   },
   "source": [
    "References: <br>\n",
    "https://github.com/rapidsai/cuml/blob/branch-0.17/notebooks/forest_inference_demo.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt0ZL4F01C3o"
   },
   "source": [
    "# Forest Inference Library (FIL)\n",
    "The forest inference library is used to load saved forest models of xgboost, lightgbm and perform inference on them (classification and regression).\n",
    "\n",
    "**Plan**\n",
    "<br>\n",
    "- Fit a model with XGBoost\n",
    "- Save model\n",
    "- Load saved model into FIL\n",
    "- Use model to infer on new data\n",
    "\n",
    "FIL works in the same way with lightgbm model.\n",
    "\n",
    "The model accepts both numpy arrays and cuDF dataframes.\n",
    "\n",
    "[forest inference library](https://docs.rapids.ai/api/cuml/stable/api.html#forest-inferencing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9413,
     "status": "ok",
     "timestamp": 1627902504679,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "mVUpHWVTK_Mc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# cuML\n",
    "# from cuml.test.utils import array_equal\n",
    "from cuml.common.import_utils import has_xgboost\n",
    "from cuml import ForestInference\n",
    "\n",
    "# sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioca1vMWL7Do"
   },
   "source": [
    "## Check for xgboost\n",
    "Checks if xgboost is present, else throw error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1627902517406,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "vOf5JB9kL_np"
   },
   "outputs": [],
   "source": [
    "if has_xgboost():\n",
    "    import xgboost as xgb\n",
    "else:\n",
    "    raise ImportError(\"Please install xgboost using the conda package,\"\n",
    "                      \" Use conda install -c conda-forge xgboost \"\n",
    "                      \"command to install xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "658wf90SMCtc"
   },
   "source": [
    "## Train helper function\n",
    "Defines a function that trains XGBoost model and returns trained model.\n",
    "\n",
    "[xgboost library](https://xgboost.readthedocs.io/en/latest/parameter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1627902519258,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "vJry33lsMhgo"
   },
   "outputs": [],
   "source": [
    "def train_xgboost_model(X_train, y_train, num_rounds, model_path):\n",
    "\n",
    "    # set xgboost model parameters\n",
    "    params = {'silent': 1, 'eval_metric':'error',\n",
    "              'objective':'binary:logistic',\n",
    "              'max_depth': 25}\n",
    "    # process inputs\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "    # train xgboost model\n",
    "    bst = xgb.train(params, dtrain, num_rounds)\n",
    "\n",
    "    # save trained xgboost model\n",
    "    bst.save_model(model_path)\n",
    "\n",
    "    return bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJTkXTTkMx8L"
   },
   "source": [
    "## Predict helper function\n",
    "Uses trained xgboost model to perform prediction and return labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1627902522268,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "ZTmLyDQ9Myys"
   },
   "outputs": [],
   "source": [
    "def predict_xgboost_model(X_validation, y_validation, xgb_model):\n",
    "\n",
    "    # process input\n",
    "    dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "    # predict using xgboost model\n",
    "    xgb_preds = xgb_model.predict(dvalidation)\n",
    "\n",
    "    # convert predicted values from xgboost into class labels\n",
    "    xgb_preds = np.around(xgb_preds)\n",
    "    \n",
    "    return xgb_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iVA26pJZMz0s"
   },
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1627902523523,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "adPPhXiANAX7"
   },
   "outputs": [],
   "source": [
    "n_rows = 10000\n",
    "n_columns = 100\n",
    "n_categories = 2\n",
    "\n",
    "# object that generates random numbers drawn from a variety of probability distributions\n",
    "random_state = np.random.RandomState(43210)\n",
    "\n",
    "# enter path to directory where trained model will be saved\n",
    "model_path = 'xgb.model'\n",
    "\n",
    "# num of iterations for which the model is trained\n",
    "num_rounds = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AmnyxykNCqy"
   },
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1627902525518,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "cQcpa0qhNEhl"
   },
   "outputs": [],
   "source": [
    "# create dataset (n-class classification problem)\n",
    "X, y = make_classification(n_samples=n_rows,\n",
    "                           n_features=n_columns,\n",
    "                           n_informative=int(n_columns/5),\n",
    "                           n_classes=n_categories,\n",
    "                           random_state=random_state)\n",
    "train_size = 0.8\n",
    "\n",
    "# convert dataset to np.float32\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# split dataset into training and validation splits\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size=train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_nzcVywNIGD"
   },
   "source": [
    "## Train and Predict model\n",
    "Invoke function to train model and get predictions to validate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5250,
     "status": "ok",
     "timestamp": 1627902532303,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "q-j2Do8ENIyJ",
    "outputId": "6257b8da-8864-4f3b-d2df-7eae5365bcc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:32:55] WARNING: /opt/conda/envs/rapids/conda-bld/xgboost_1639022671260/work/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train xgboost model\n",
    "xgboost_model = train_xgboost_model(X_train, y_train, num_rounds, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1627902532304,
     "user": {
      "displayName": "A B",
      "photoUrl": "",
      "userId": "01224062562146721531"
     },
     "user_tz": -480
    },
    "id": "T6i76L_MNKDF",
    "outputId": "76baed76-91b5-4b54-fa2d-76495c8a045f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 ms, sys: 0 ns, total: 11.5 ms\n",
      "Wall time: 5.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test xgboost model\n",
    "trained_model_preds = predict_xgboost_model(X_validation, y_validation, xgboost_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6Ml35irNNlF"
   },
   "source": [
    "## Load Forest Inference Library (FIL)\n",
    "The load function of the ForestInference class accepts the following parameters:\n",
    "\n",
    "filename : str <br>\n",
    "    Path to saved model file in a treelite-compatible format\n",
    "    <br>\n",
    "    (See https://treelite.readthedocs.io/en/latest/treelite-api.html\n",
    "    \n",
    "\n",
    "output_class : bool <br>\n",
    "    If true, return a 1 or 0 depending on whether the raw prediction\n",
    "    exceeds the threshold.\n",
    "    <br>\n",
    "    If False, just return the raw prediction.\n",
    "    \n",
    "\n",
    "threshold : float <br>\n",
    "    Cutoff value above which a prediction is set to 1.0\n",
    "    <br>\n",
    "    Only used if the model is classification and `output_class` is `True`\n",
    "\n",
    "\n",
    "algo : string name of the algo from (from algo_t enum)\n",
    "<br>\n",
    "\n",
    "- 'NAIVE' - simple inference using shared memory\n",
    "- 'TREE_REORG' - similar to naive but trees rearranged to be more coalescing-friendly\n",
    "- 'BATCH_TREE_REORG' - similar to TREE_REORG but predicting  multiple rows per thread block\n",
    "\n",
    "<br>\n",
    "model_type : str\n",
    "<br>\n",
    "    Format of saved treelite model to load.\n",
    "    <br>\n",
    "    Can be 'xgboost', 'lightgbm'\n",
    "\n",
    "\n",
    "## Loaded saved model\n",
    "Use FIL to load the saved xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iel7Vy38NRIm"
   },
   "outputs": [],
   "source": [
    "fm = ForestInference.load(filename=model_path,\n",
    "                          algo='BATCH_TREE_REORG',\n",
    "                          output_class=True,\n",
    "                          threshold=0.50,\n",
    "                          model_type='xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTjtEtFFNTV9"
   },
   "source": [
    "## Predict using FIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-0DrW_XXNVH0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 93 Âµs, sys: 2.56 ms, total: 2.65 ms\n",
      "Wall time: 1.75 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# perform prediction on the model loaded from path\n",
    "fil_preds = fm.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gSTtOdPNWRt"
   },
   "source": [
    "## Evaluate results\n",
    "Verify predictions for original and FIL model match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0Dzoh2NYNXr0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of predictions obtained from xgboost :  (2000,)\n",
      "The shape of predictions obtained from FIL :  (2000,)\n",
      "Are the predictions for xgboost and FIL the same :  True\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of predictions obtained from xgboost : \",(trained_model_preds).shape)\n",
    "print(\"The shape of predictions obtained from FIL : \",(fil_preds).shape)\n",
    "# print(\"Are the predictions for xgboost and FIL the same : \" ,   array_equal(trained_model_preds, fil_preds))\n",
    "print(\"Are the predictions for xgboost and FIL the same : \" ,  (trained_model_preds == fil_preds).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Forest_Inference_Demo.ipynb",
   "provenance": [
    {
     "file_id": "11M7M4wW1s9BSpMLn9TiaPqpLfauD7mnp",
     "timestamp": 1625154936737
    },
    {
     "file_id": "1rY7Ln6rEE1pOlfSHCYOVaqt8OvDO35J0",
     "timestamp": 1625154639853
    },
    {
     "file_id": "1XTKHiIcvyL5nuldx0HSL_dUa8yopzy_Y",
     "timestamp": 1568928635382
    },
    {
     "file_id": "1gUnPS2zuUOUe4YG-2iDm_Y2X5RTkgsGh",
     "timestamp": 1556293046020
    }
   ]
  },
  "kernelspec": {
   "display_name": "rapids-21.12:Python",
   "language": "python",
   "name": "conda-env-rapids-21.12-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
